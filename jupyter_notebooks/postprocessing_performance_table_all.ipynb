{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate Anomaly Maps & Performance Metrics\n",
    "\n",
    "Author(s): Peer Sch√ºtt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os, glob\n",
    "\n",
    "parent_dir = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "sys.path.append(parent_dir)\n",
    "import json\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "from autoencoder import Autoencoder\n",
    "from MultispectralImageDataset import MultispectralImageDataset\n",
    "from utils import save_img_comparisons, loss_func\n",
    "import cv2 as cv\n",
    "from utils import find_image, load_all_img_paths, labelme_plot_with_custom_cmap, set_global_random_seed\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "from labelme import utils as labelme_utils\n",
    "\n",
    "device = \"cpu\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model selection and image prediction\n",
    "\n",
    "### Select the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pretrained_model_name = \"2025-04-18_16-14-34_musero_autoencoder_NIR\" # NIR 1024\n",
    "# pretrained_model_name = \"2025-04-19_12-45-55_musero_autoencoder_NIR\" # NIR 2048\n",
    "pretrained_model_name = \"2025-04-18_09-48-55_musero_autoencoder_VIS\" # VIS 1024\n",
    "# pretrained_model_name = \"2025-04-24_13-32-54_musero_autoencoder_VIS\" # VIS 2048\n",
    "\n",
    "img_type = \"VIS\" if \"VIS\" in pretrained_model_name else \"NIR\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get all image names for which we have labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelled_files_folder_path = \"../sample_images/\"\n",
    "all_labelled_file_names = []\n",
    "for filename in glob.glob(f\"{labelled_files_folder_path}*.json\"):\n",
    "    if (img_type in filename) and (\"2025\" in filename):\n",
    "        all_labelled_file_names.append(os.path.basename(filename).replace(\".json\", \"\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parent folder of all the data folders\n",
    "data_folder = \"../sample_images/\"\n",
    "\n",
    "pretrained_model_folder = \"../trained_models/\"\n",
    "pretrained_model_full_path = pretrained_model_folder + pretrained_model_name\n",
    "\n",
    "whole_dict = None\n",
    "with open(pretrained_model_full_path+\".json\") as f:\n",
    "    whole_dict = json.load(f)\n",
    "config = whole_dict[\"config\"]\n",
    "config[\"batch_size\"] = int(np.min([config[\"batch_size\"], len(all_labelled_file_names)]))\n",
    "dense_layer_dim = config[\"dense_layer_dim\"]\n",
    "\n",
    "set_global_random_seed(config)\n",
    "\n",
    "transform = transforms.Compose([\n",
    "        transforms.CenterCrop([config['img_size_x'], config['img_size_y']])\n",
    "    ])\n",
    "model = Autoencoder(**config).to(device)\n",
    "\n",
    "model.load_state_dict(torch.load(pretrained_model_full_path+\".pth\", weights_only=True))\n",
    "model.eval()\n",
    "\n",
    "dataset_params = {\n",
    "    'transform': transform,\n",
    "    'img_type': config[\"img_type\"],\n",
    "    'channels_to_use': config['channels_to_use'],\n",
    "    'device': device,\n",
    "    'overfit': False,\n",
    "    'augment_data': False\n",
    "}   \n",
    "\n",
    "# Create data loaders with common parameters\n",
    "dataloader_params = {\n",
    "    'batch_size': config['batch_size'],\n",
    "    'num_workers': 4,\n",
    "    'pin_memory': True\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load all original .npy images for each labelled image we have "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_img_paths = [find_image(testing_img_name) for testing_img_name in all_labelled_file_names]\n",
    " \n",
    "test_dataset = MultispectralImageDataset(test_img_paths, **dataset_params)\n",
    "test_data_loader = DataLoader(test_dataset, shuffle=False, **dataloader_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_save_path = \"../images_paper/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict all images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    for batch_idx, (corrected_images, raw_images, img_full_path) in enumerate(tqdm(test_data_loader)):\n",
    "        raw_images = raw_images.to(device)\n",
    "        batch_size = raw_images.shape[0]\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(raw_images)\n",
    "\n",
    "        loss_image = loss_func(raw_images, outputs, per_img_and_pixel=True).cpu().detach().numpy()\n",
    "\n",
    "        # save_img_comparisons(\n",
    "        #     raw_images, outputs, img_full_path, [0,1,2,3,4,5,6,7], prefix=f\"{img_save_path}channel_comparison_{testing_img_name}.jpg\", dpi = 100\n",
    "        # )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Postprocessing\n",
    "\n",
    "### Load thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresholds = np.load(f\"{pretrained_model_full_path}/thresholds_val_95.npy\", allow_pickle=True)\n",
    "thresholds_reshaped = thresholds[:, np.newaxis, np.newaxis]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What component analysis do you want to do?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### for component analysis ###\n",
    "# specific channels\n",
    "use_RGB_only = False # default False\n",
    "use_single_channel = False  # default False\n",
    "single_channel = 1\n",
    "\n",
    "# votings\n",
    "use_intersection = False # default False\n",
    "use_majority = False # default False\n",
    "use_union = True # default True\n",
    "assert (int(use_intersection) + int(use_majority) + int(use_union)) == 1, \"You can only use one voting approach!\"\n",
    "\n",
    "# denoising\n",
    "use_denoising = True # default True\n",
    "\n",
    "save_images_for_paper = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if use_RGB_only is True:\n",
    "    print(\"Performing ablation study: \", \"Only using RGB channels\")\n",
    "    \n",
    "    if img_type != \"VIS\":\n",
    "        print(\"A VIS model is required!\")\n",
    "        exit(-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform postprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# threshold the values\n",
    "# loss_image_squeeze = loss_image\n",
    "thresholded_loss_image = loss_image.copy()\n",
    "thresholded_loss_image[loss_image<thresholds_reshaped] = 0.\n",
    "thresholded_loss_image[loss_image>=thresholds_reshaped] = 1.\n",
    "\n",
    "if use_union is True:\n",
    "    vote_threshold = 1\n",
    "elif use_majority is True:\n",
    "    if use_RGB_only is True:\n",
    "        vote_threshold = 2\n",
    "    elif use_single_channel is True:\n",
    "        vote_threshold = 1\n",
    "    else:\n",
    "        vote_threshold = 4\n",
    "elif use_intersection is True:\n",
    "    if use_RGB_only is True:\n",
    "        vote_threshold = 3\n",
    "    elif use_single_channel is True:\n",
    "        vote_threshold = 1\n",
    "    else:\n",
    "        vote_threshold = 8\n",
    "\n",
    "# perform voting\n",
    "if use_RGB_only:\n",
    "    channel_sum = np.sum(thresholded_loss_image[:,[0,2,6]], axis=1)\n",
    "elif use_single_channel:\n",
    "    channel_sum = thresholded_loss_image[:,single_channel].copy()\n",
    "else:\n",
    "    channel_sum = np.sum(thresholded_loss_image[:,0:8], axis=1)\n",
    "\n",
    "threshold_vote = (channel_sum >= vote_threshold).astype(np.uint8)\n",
    "\n",
    "postprocessing_result = threshold_vote.copy()\n",
    "\n",
    "if use_denoising is True:\n",
    "    # perform denoising\n",
    "    \n",
    "    ## MORPHOLOGICAL\n",
    "    # https://docs.opencv.org/4.x/d9/d61/tutorial_py_morphological_ops.html\n",
    "    open_kernel = np.ones((2,2),np.uint8)\n",
    "    # opening_vote = cv.morphologyEx(threshold_vote, cv.MORPH_OPEN, open_kernel)\n",
    "    opening_vote = np.stack([cv.morphologyEx(img, cv.MORPH_OPEN, open_kernel) \n",
    "                            for img in threshold_vote])\n",
    "\n",
    "    # close_kernel = np.ones((3,3),np.uint8)\n",
    "    # # closing_vote = cv.morphologyEx(opening_vote, cv.MORPH_CLOSE, close_kernel, iterations=2)\n",
    "    # closing_vote = np.stack([cv.morphologyEx(img, cv.MORPH_CLOSE, close_kernel, iterations=1) \n",
    "    #                         for img in opening_vote])\n",
    "    \n",
    "    # postprocessing_result = closing_vote.copy()\n",
    "    # postprocessing_result = opening_vote.copy()\n",
    "    \n",
    "    ## CV MEDIAN BLUR\n",
    "    median = np.stack([cv.medianBlur(img, 5)\n",
    "                            for img in opening_vote])  # 5x5 kernel\n",
    "    # median_tresh = np.stack([cv.medianBlur(img, 5)\n",
    "    #                         for img in threshold_vote])  # 5x5 kernel\n",
    "    postprocessing_result = median.copy()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if save_images_for_paper is True:\n",
    "    channel_id_for_paper = 1\n",
    "    batch_id_to_save = 0\n",
    "    testing_img_name = Path(test_img_paths[batch_id_to_save]).stem\n",
    "\n",
    "    # input image\n",
    "    input_image = np.load(test_img_paths[batch_id_to_save])\n",
    "    plt.axis('off')\n",
    "    plt.imshow(input_image, cmap=\"viridis\")\n",
    "    plt.savefig(f'{img_save_path}input_{testing_img_name}.jpg', dpi = 100, bbox_inches=\"tight\", pad_inches = 0)\n",
    "    plt.close()\n",
    "\n",
    "    # reconstructed image channel_id_for_paper\n",
    "    out_pan_image = outputs[batch_id_to_save,channel_id_for_paper,:,:].cpu().detach().numpy()\n",
    "    plt.axis('off')\n",
    "    plt.imshow(out_pan_image, cmap=\"viridis\")\n",
    "    plt.savefig(f'{img_save_path}recon_c{channel_id_for_paper}_{testing_img_name}.jpg', bbox_inches='tight', dpi = 100, pad_inches = 0)\n",
    "    plt.close()\n",
    "\n",
    "    # loss image channel_id_for_paper\n",
    "    plt.axis('off')\n",
    "    plt.imshow(loss_image[batch_id_to_save,channel_id_for_paper,:,:], cmap=\"viridis_r\")\n",
    "    plt.savefig(f'{img_save_path}loss_c{channel_id_for_paper}_{testing_img_name}.jpg', bbox_inches='tight', dpi = 100, pad_inches = 0)\n",
    "    plt.close()\n",
    "\n",
    "    # thresholded image channel_id_for_paper\n",
    "    plt.axis('off')\n",
    "    plt.imshow(thresholded_loss_image[batch_id_to_save, channel_id_for_paper,:,:], cmap=\"viridis_r\")\n",
    "    plt.savefig(f'{img_save_path}threshold_c{channel_id_for_paper}_{testing_img_name}.jpg', bbox_inches='tight', dpi = 100, pad_inches = 0)\n",
    "    plt.close()\n",
    "\n",
    "    # voting image\n",
    "    plt.axis('off')\n",
    "    plt.imshow(threshold_vote[batch_id_to_save,:,:], cmap=\"viridis_r\")\n",
    "    plt.savefig(f'{img_save_path}vote{vote_threshold}_{testing_img_name}.jpg', bbox_inches='tight', dpi = 100, pad_inches = 0)\n",
    "    plt.close()\n",
    "    \n",
    "    # denoised image\n",
    "    plt.axis('off')\n",
    "    plt.imshow(postprocessing_result[batch_id_to_save], cmap=\"viridis_r\")\n",
    "    plt.savefig(f'{img_save_path}morph_{testing_img_name}.jpg', bbox_inches='tight', dpi = 100, pad_inches = 0)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.axis(\"off\")\n",
    "plt.imshow(postprocessing_result[0], cmap=\"viridis_r\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load labelled images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_keys = ['ErdeXDuenger_1p1_100', 'ErdeXDuenger_1p1_50', 'ErdeXDuenger_1p4_100', 'ErdeXDuenger_1p4_50', 'Erde_100', 'Erde_50', 'Sand_20', 'Sand_50', 'Waschpulver_25', 'Waschpulver_50', \"Ethanol\", 'Spectralon_x']\n",
    "label_name_to_value = dict(zip(evaluate_keys, np.arange(2, len(evaluate_keys)+2)))\n",
    "\n",
    "value_to_label_name = {v: k for k, v in label_name_to_value.items()}\n",
    "\n",
    "# keys_present = list(set(evaluate_keys) & set(label_name_to_value.keys()))\n",
    "# labels_to_evaluate = [label_name_to_value[key] for key in keys_present]\n",
    "\n",
    "batched_label_mask = np.zeros(postprocessing_result.shape, dtype=np.int8)\n",
    "batched_label_mask_road = np.zeros(postprocessing_result.shape, dtype=np.int8)\n",
    "\n",
    "for idx, filename in enumerate(all_labelled_file_names):\n",
    "# for idx, filename in enumerate([testing_img_name]):\n",
    "    json_file = labelled_files_folder_path + filename + \".json\"\n",
    "\n",
    "    data = json.load(open(json_file))\n",
    "    input_img = labelme_utils.img_b64_to_arr(data.get(\"imageData\"))\n",
    "\n",
    "    label_mask = np.zeros(input_img.shape, dtype=np.int8)\n",
    "    label_mask_road = np.zeros(input_img.shape, dtype=np.int8)\n",
    "\n",
    "    for i, shape in enumerate(data['shapes']):\n",
    "        if shape[\"label\"] == \"road\":\n",
    "            points = shape['points']\n",
    "            points = np.array(points, dtype=np.int16)\n",
    "            shape_mask = labelme_utils.shape_to_mask(\n",
    "                input_img.shape, points, shape_type=shape['shape_type']\n",
    "            )\n",
    "            label_mask[shape_mask] = 1\n",
    "            label_mask_road[shape_mask] = 1\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "    # Fill in the labeled regions\n",
    "    for i, shape in enumerate(data['shapes']):\n",
    "        \n",
    "        label = shape[\"label\"]    \n",
    "        points = shape['points']\n",
    "        # Convert to numpy array\n",
    "        points = np.array(points, dtype=np.int32)\n",
    "        \n",
    "        # Create binary mask for this shape (1 for shape, 0 elsewhere)\n",
    "        shape_mask = labelme_utils.shape_to_mask(\n",
    "            input_img.shape, points, shape_type=shape['shape_type']\n",
    "        )\n",
    "        mask_value = 0\n",
    "        try: \n",
    "            mask_value = label_name_to_value[label]\n",
    "        except:\n",
    "            mask_value = 0\n",
    "            if label != \"road\":\n",
    "                print(\"No entry found for \", label) \n",
    "            continue\n",
    "        \n",
    "        # Set class index (leave 0 and 1 for background and road)\n",
    "        label_mask[shape_mask] = mask_value   \n",
    "    \n",
    "    label_mask_road = torch.tensor(label_mask_road)\n",
    "    label_mask_road = transform(label_mask_road)\n",
    "    label_mask_road = label_mask_road.numpy()\n",
    "    \n",
    "    label_mask = torch.tensor(label_mask)\n",
    "    label_mask = transform(label_mask)\n",
    "    label_mask = label_mask.numpy()\n",
    "    \n",
    "    batched_label_mask[idx] = label_mask\n",
    "    batched_label_mask_road[idx] = label_mask_road\n",
    "\n",
    "\n",
    "# how many pixels are on the road?\n",
    "# y_pred = postprocessing_result\n",
    "road_mask = batched_label_mask_road & postprocessing_result\n",
    "b = np.logical_and(batched_label_mask_road, postprocessing_result)\n",
    "    \n",
    "final_prediction = road_mask.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# road mask\n",
    "plt.imshow(batched_label_mask_road[0,:,:])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# postprocessing result before road mask is applied\n",
    "plt.imshow(postprocessing_result[0,:,:])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# postprocessing result after road mask is applied\n",
    "plt.imshow(road_mask[0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if save_images_for_paper is True:\n",
    "    plt.axis('off')\n",
    "    plt.imshow(road_mask[batch_id_to_save], cmap=\"viridis_r\")\n",
    "    plt.savefig(f'{img_save_path}final_AoI_{testing_img_name}.jpg', bbox_inches='tight', dpi = 100, pad_inches = 0)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate performance measures\n",
    "\n",
    "### Define which substances we want to test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only report these labels for the paper\n",
    "# the spectralon isn't a substance we want to test\n",
    "value_to_paper_label_name = {\n",
    "2: 'SoFe 1p1 100',\n",
    "3: 'SoFe 1p1 50',\n",
    "4: 'SoFe 1p4 100',\n",
    "5: 'SoFe 1p4 50',\n",
    "6: 'So 100',\n",
    "7: 'So 50',\n",
    "8: 'Sa 20',\n",
    "9: 'Sa 50',\n",
    "10: 'WP 25',\n",
    "11: 'WP 50',\n",
    "12: 'Ethanol',\n",
    "13: 'Spectralon'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance across images over all classes\n",
    "\n",
    "We can use these to report all measures (Precision, Recall, F1, IoU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batched_TP_across_all_classes = np.zeros((len(all_labelled_file_names)))\n",
    "batched_FP_across_all_classes = np.zeros((len(all_labelled_file_names)))\n",
    "batched_FN_across_all_classes = np.zeros((len(all_labelled_file_names)))\n",
    "batched_TN_across_all_classes = np.zeros((len(all_labelled_file_names)))\n",
    "\n",
    "for batch_idx, label_mask in enumerate(batched_label_mask): \n",
    "    \n",
    "    y_pred = final_prediction[batch_idx]\n",
    "    \n",
    "    gt_mask_all_classes = np.zeros_like(y_pred)\n",
    "    gt_mask_all_classes[np.isin(label_mask, list(value_to_paper_label_name.keys()))] = 1\n",
    "    \n",
    "    TP_across_all_classes = np.sum((y_pred == 1) & gt_mask_all_classes)\n",
    "    FP_across_all_classes = np.sum((y_pred == 1) & ~gt_mask_all_classes)\n",
    "    FN_across_all_classes = np.sum((y_pred == 0) & gt_mask_all_classes)\n",
    "    TN_across_all_classes = np.sum((y_pred == 0) & ~gt_mask_all_classes)\n",
    "    \n",
    "    batched_TP_across_all_classes[batch_idx] = TP_across_all_classes\n",
    "    batched_FP_across_all_classes[batch_idx] = FP_across_all_classes\n",
    "    batched_FN_across_all_classes[batch_idx] = FN_across_all_classes\n",
    "    batched_TN_across_all_classes[batch_idx] = TN_across_all_classes\n",
    "\n",
    "TP_sum_all_images_across_all_classes = np.sum(batched_TP_across_all_classes)\n",
    "FP_sum_all_images_across_all_classes = np.sum(batched_FP_across_all_classes)\n",
    "FN_sum_all_images_across_all_classes = np.sum(batched_FN_across_all_classes)\n",
    "TN_sum_all_images_across_all_classes = np.sum(batched_TN_across_all_classes)\n",
    "\n",
    "precision_all_images_across_all_classes = TP_sum_all_images_across_all_classes / (TP_sum_all_images_across_all_classes + FP_sum_all_images_across_all_classes) if (TP_sum_all_images_across_all_classes + FP_sum_all_images_across_all_classes) > 0 else 0\n",
    "recall_all_images_across_all_classes = TP_sum_all_images_across_all_classes / (TP_sum_all_images_across_all_classes + FN_sum_all_images_across_all_classes) if (TP_sum_all_images_across_all_classes + FN_sum_all_images_across_all_classes) > 0 else 0\n",
    "F1_all_images_across_all_classes = 2 * precision_all_images_across_all_classes * recall_all_images_across_all_classes / (precision_all_images_across_all_classes + recall_all_images_across_all_classes)\n",
    "F2_all_images_across_all_classes = 5 * precision_all_images_across_all_classes * recall_all_images_across_all_classes / (4*precision_all_images_across_all_classes + recall_all_images_across_all_classes)\n",
    "iou_all_images_across_all_classes = TP_sum_all_images_across_all_classes / (TP_sum_all_images_across_all_classes + FP_sum_all_images_across_all_classes + FN_sum_all_images_across_all_classes) if (TP_sum_all_images_across_all_classes + FP_sum_all_images_across_all_classes + FN_sum_all_images_across_all_classes) > 0 else 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LATEX: Precision / Recall / F1 / IoU overall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names = \" & Precision & Recall & F1 & F2 & IoU\"\n",
    "entries = f\"{img_type} {dense_layer_dim} & {precision_all_images_across_all_classes:.3f} & {recall_all_images_across_all_classes:.3f} & {F1_all_images_across_all_classes:.3f} & {F2_all_images_across_all_classes:.3f} & {iou_all_images_across_all_classes:.3f}\"\n",
    "\n",
    "print(f\"RESULTS for {pretrained_model_name}\")\n",
    "print(column_names +  \"\\n\" + entries)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance per image and class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "batched_results = []\n",
    "\n",
    "batched_TP = np.zeros((len(all_labelled_file_names), max(label_name_to_value.values())+1))\n",
    "batched_FP = np.zeros((len(all_labelled_file_names), max(label_name_to_value.values())+1))\n",
    "batched_FN = np.zeros((len(all_labelled_file_names), max(label_name_to_value.values())+1))\n",
    "batched_TN = np.zeros((len(all_labelled_file_names), max(label_name_to_value.values())+1))\n",
    "\n",
    "for batch_idx, label_mask in enumerate(batched_label_mask):\n",
    "    \n",
    "    y_true = label_mask\n",
    "    y_pred = final_prediction[batch_idx]\n",
    "    \n",
    "    # Assuming:\n",
    "    # y_true: ground truth with multiple classes (2-13)\n",
    "    # y_pred: binary prediction (0/1)\n",
    "    results = {}\n",
    "    for class_id in label_name_to_value.values():\n",
    "        # Create binary mask for this ground truth class\n",
    "        gt_mask = (y_true == class_id)\n",
    "        \n",
    "        # Calculate metrics for this class\n",
    "        TP = np.sum((y_pred == 1) & gt_mask)\n",
    "        FP = np.sum((y_pred == 1) & ~gt_mask)\n",
    "        FN = np.sum((y_pred == 0) & gt_mask)\n",
    "        TN = np.sum((y_pred == 0) & ~gt_mask)\n",
    "                \n",
    "        # Calculate metrics\n",
    "        precision = TP / (TP + FP) if (TP + FP) > 0 else 0\n",
    "        recall = TP / (TP + FN) if (TP + FN) > 0 else 0\n",
    "        iou = TP / (TP + FP + FN) if (TP + FP + FN) > 0 else 0\n",
    "        \n",
    "        # Store results\n",
    "        results[class_id] = {\n",
    "            'true_positives': TP,\n",
    "            'false_positives': FP,\n",
    "            'false_negatives': FN,\n",
    "            'precision': precision,\n",
    "            'recall': recall,\n",
    "            'iou': iou\n",
    "        }    \n",
    "        \n",
    "        batched_TP[batch_idx, class_id] = TP\n",
    "        batched_FP[batch_idx, class_id] = FP\n",
    "        batched_FN[batch_idx, class_id] = FN\n",
    "        batched_TN[batch_idx, class_id] = TN\n",
    "        \n",
    "    # # Print results\n",
    "    # for class_id, metrics in results.items():\n",
    "    #     print(f\"Class {value_to_label_name[class_id]}:\")\n",
    "    #     print(f\"  TP: {metrics['true_positives']}, FN: {metrics['false_negatives']}\")\n",
    "    #     print(f\"  FP: {metrics['false_positives']}\")\n",
    "    #     # print(f\"  Precision: {metrics['precision']:.4f}\")\n",
    "    #     print(f\"  Recall: {metrics['recall']:.4f}\")\n",
    "    #     # print(f\"  IoU: {metrics['iou']:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance across images over specific class\n",
    "\n",
    "Only take Recall from these values!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_over_all_images = {}\n",
    "results_over_all_images_specific_classes = {}\n",
    "TP_sum_all_images, FP_sum_all_images, FN_sum_all_images, TN_sum_all_images = 0,0,0,0\n",
    "\n",
    "for class_id in label_name_to_value.values():\n",
    "    TP_sum = np.sum(batched_TP[:,class_id])\n",
    "    FP_sum = np.sum(batched_FP[:,class_id])\n",
    "    FN_sum = np.sum(batched_FN[:,class_id])\n",
    "    TN_sum = np.sum(batched_TN[:,class_id])\n",
    "    \n",
    "    TP_sum_all_images += TP_sum\n",
    "    FP_sum_all_images += FP_sum\n",
    "    FN_sum_all_images += FN_sum\n",
    "    TN_sum_all_images += TN_sum\n",
    "    \n",
    "    # Calculate metrics\n",
    "    precision_all = TP_sum / (TP_sum + FP_sum) if (TP_sum + FP_sum) > 0 else 0\n",
    "    recall_all = TP_sum / (TP_sum + FN_sum) if (TP_sum + FN_sum) > 0 else 0\n",
    "    iou_all = TP_sum / (TP_sum + FP_sum + FN_sum) if (TP_sum + FP_sum + FN_sum) > 0 else 0\n",
    "    \n",
    "    results_over_all_images[class_id] = {\n",
    "        'true_positives': TP_sum,\n",
    "        'false_positives': FP_sum,\n",
    "        'false_negatives': FN_sum,\n",
    "        \"true_negatives\": TN_sum,\n",
    "        'precision': precision_all,\n",
    "        'recall': recall_all,\n",
    "        'iou': iou_all\n",
    "    }\n",
    "\n",
    "# Calculate metrics\n",
    "precision_all_images = TP_sum_all_images / (TP_sum_all_images + FP_sum_all_images) if (TP_sum_all_images + FP_sum_all_images) > 0 else 0\n",
    "recall_all_images = TP_sum_all_images / (TP_sum_all_images + FN_sum_all_images) if (TP_sum_all_images + FN_sum_all_images) > 0 else 0\n",
    "F1_all_images = 2 * precision_all_images * recall_all_images / (precision_all_images + recall_all_images)\n",
    "iou_all_images = TP_sum_all_images / (TP_sum_all_images + FP_sum_all_images + FN_sum_all_images) if (TP_sum_all_images + FP_sum_all_images + FN_sum_all_images) > 0 else 0\n",
    "    \n",
    "results_over_all_images_specific_classes = {\n",
    "    'true_positives': TP_sum_all_images,\n",
    "    'false_positives': FP_sum_all_images,\n",
    "    'false_negatives': FN_sum_all_images,\n",
    "    \"true_negatives\": TN_sum_all_images,\n",
    "    'precision': precision_all_images,\n",
    "    'recall': recall_all_images,\n",
    "    'iou': iou_all_images\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LATEX: Print resulting table for paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"RESULTS for {pretrained_model_name}\")\n",
    "\n",
    "import pandas as pd\n",
    "# Extract only the recall values for each class\n",
    "recall_values = {f\"{img_type} {dense_layer_dim}\": {f\"{value_to_paper_label_name[class_id]}\": results_over_all_images[class_id]['recall'] for class_id in value_to_paper_label_name.keys()}}\n",
    "\n",
    "# recall_values_all = {\"Overall\": results_over_all_images_specific_classes['recall']}\n",
    "\n",
    "# # merge both dicts with \"Overall\" as first entry\n",
    "# recall_values[f\"{img_type} {dense_layer_dim}\"] = {**recall_values_all, **recall_values[f\"{img_type} {dense_layer_dim}\"]}\n",
    "\n",
    "# Create the DataFrame with classes as columns\n",
    "df = pd.DataFrame(recall_values).T\n",
    "# Format to 3 decimal places\n",
    "df = df.round(3)\n",
    "# Convert to LaTeX table\n",
    "# latex_table = df.to_latex(index=True, index_names=False)\n",
    "# print(latex_table)\n",
    "# For a more professional table with booktabs style\n",
    "latex_table_booktabs = df.to_latex(\n",
    "    index=True,\n",
    "    index_names=False,\n",
    "    caption=\"Recall Values by Class\",\n",
    "    label=\"tab:recall_values\",\n",
    "    position=\"htbp\",\n",
    "    column_format=\"l\" + \"c\" * len(df.columns), \n",
    "    float_format=\"{:0.3f}\".format\n",
    ")\n",
    "print(latex_table_booktabs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spectrae",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
