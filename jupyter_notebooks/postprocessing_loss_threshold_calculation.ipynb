{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate the Thresholds for each Image Channel\n",
    "\n",
    "Author(s): Peer Schütt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "\n",
    "parent_dir = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "sys.path.append(parent_dir)\n",
    "import json\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "from autoencoder import Autoencoder\n",
    "from MultispectralImageDataset import MultispectralImageDataset\n",
    "from utils import load_all_img_paths, loss_func, set_global_random_seed\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "DEVICE = \"cpu\"\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_model_folder = \"trained_models/\"\n",
    "\n",
    "# pretrained_model_name = \"2025-04-18_16-14-34_musero_autoencoder_NIR\" # NIR 1024\n",
    "# pretrained_model_name = \"2025-04-19_12-45-55_musero_autoencoder_NIR\" # NIR 2048\n",
    "# pretrained_model_name = \"2025-04-18_09-48-55_musero_autoencoder_VIS\" # VIS 1024\n",
    "pretrained_model_name = \"2025-04-24_13-32-54_musero_autoencoder_VIS\" # VIS 2048\n",
    "pretrained_model_full_path = pretrained_model_folder + pretrained_model_name\n",
    "\n",
    "pretrained_model_location_dict = pretrained_model_full_path+\".json\"\n",
    "pretrained_model_location_weights = pretrained_model_full_path+\".pth\"\n",
    "\n",
    "model_precomputes_save_folder_path = f\"trained_models/{pretrained_model_name}/\"\n",
    "Path(model_precomputes_save_folder_path).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "whole_dict = None\n",
    "with open(pretrained_model_location_dict) as f:\n",
    "    whole_dict = json.load(f)\n",
    "config = whole_dict[\"config\"]\n",
    "\n",
    "set_global_random_seed(config)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load / calculate loss values for the train/val/test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.isfile(f\"{model_precomputes_save_folder_path}all_train_losses.npy\") and os.path.isfile(f\"{model_precomputes_save_folder_path}all_val_losses.npy\") and os.path.isfile(f\"{model_precomputes_save_folder_path}all_test_losses.npy\"):\n",
    "    print(\"Loading precomputed losses!\")\n",
    "    all_train_losses = np.load(f\"{model_precomputes_save_folder_path}all_train_losses.npy\", allow_pickle=True)\n",
    "    print(\"Loaded train losses!\")\n",
    "    all_val_losses = np.load(f\"{model_precomputes_save_folder_path}all_val_losses.npy\", allow_pickle=True)\n",
    "    print(\"Loaded val losses!\")\n",
    "    all_test_losses = np.load(f\"{model_precomputes_save_folder_path}all_test_losses.npy\", allow_pickle=True)\n",
    "    print(\"Loaded test losses!\")\n",
    "    \n",
    "else:\n",
    "    print(\"Computing new losses!\")\n",
    "\n",
    "    transform = transforms.Compose([\n",
    "            transforms.CenterCrop([config['img_size_x'], config['img_size_y']])\n",
    "        ])\n",
    "    model = Autoencoder(**config).to(DEVICE)\n",
    "\n",
    "    model.load_state_dict(torch.load(pretrained_model_location_weights, weights_only=True))\n",
    "    model.eval()\n",
    "\n",
    "    dataset_params = {\n",
    "        'transform': transform,\n",
    "        'img_type': config[\"img_type\"],\n",
    "        'channels_to_use': config['channels_to_use'],\n",
    "        'device': DEVICE,\n",
    "        'overfit': False,\n",
    "        'augment_data': False\n",
    "    }   \n",
    "\n",
    "    # Create data loaders with common parameters\n",
    "    dataloader_params = {\n",
    "        'batch_size': config['batch_size'],\n",
    "        'num_workers': 4,\n",
    "        'pin_memory': True\n",
    "    }\n",
    "\n",
    "\n",
    "    from utils import sample_data_paths # import all image paths\n",
    "    import os.path\n",
    "\n",
    "    # Combine training folders\n",
    "    train_folder = [\n",
    "        *sample_data_paths.values(),\n",
    "    ]\n",
    "\n",
    "    # Load and prepare datasets\n",
    "    train_img_paths = load_all_img_paths(train_folder, config[\"img_type\"], split=\"train\")\n",
    "\n",
    "    # Initialize datasets\n",
    "    train_val_dataset = MultispectralImageDataset(train_img_paths, **dataset_params)\n",
    "\n",
    "    # Calculate split sizes\n",
    "    dataset_size = len(train_val_dataset)\n",
    "    val_size = int(np.ceil(dataset_size * config['val_split']))\n",
    "    train_size = dataset_size - val_size\n",
    "\n",
    "    # Split dataset\n",
    "    train_set, val_set = torch.utils.data.random_split(\n",
    "        train_val_dataset,\n",
    "        [train_size, val_size]\n",
    "    )\n",
    "\n",
    "    # Create data loaders with common parameters\n",
    "    dataloader_params = {\n",
    "        'batch_size': config['batch_size'],\n",
    "        'num_workers': 4,\n",
    "        'pin_memory': True\n",
    "    }\n",
    "\n",
    "    train_data_loader = DataLoader(train_set, shuffle=True, **dataloader_params)\n",
    "    val_data_loader = DataLoader(val_set, shuffle=False, **dataloader_params)\n",
    "\n",
    "    # Prepare test dataset\n",
    "    # test_folder = [old_data_paths['fss_test']]\n",
    "    test_folder = [\n",
    "        *sample_data_paths.values(), \n",
    "    ]\n",
    "    test_img_paths = load_all_img_paths(test_folder, config[\"img_type\"], split=\"test\")\n",
    "    test_dataset = MultispectralImageDataset(test_img_paths, **dataset_params)\n",
    "    test_data_loader = DataLoader(test_dataset, shuffle=False, **dataloader_params)\n",
    "\n",
    "    def channel_loss(model, dataloader, device=DEVICE):\n",
    "        model.eval()\n",
    "        channel_losses = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for _, raw_images, _ in tqdm(dataloader):\n",
    "                raw_images = raw_images.to(device)\n",
    "                outputs = model(raw_images)\n",
    "                \n",
    "                channel_loss = loss_func(raw_images, outputs, per_img_and_pixel=True)\n",
    "                channel_losses.append(channel_loss.cpu())\n",
    "                \n",
    "        return channel_losses\n",
    "\n",
    "    # train_losses = channel_loss(model, train_data_loader)\n",
    "    # reshaped_list = []\n",
    "    # for tensor in train_losses:\n",
    "    #     batch_size = tensor.shape[0]\n",
    "    #     reshaped = tensor.reshape(-1, 9, tensor.shape[2], tensor.shape[3])\n",
    "    #     reshaped_list.append(reshaped)\n",
    "    # all_train_losses = torch.cat(reshaped_list, dim=0).numpy()\n",
    "\n",
    "    val_losses = channel_loss(model, val_data_loader)\n",
    "    reshaped_list = []\n",
    "    for tensor in val_losses:\n",
    "        batch_size = tensor.shape[0]\n",
    "        reshaped = tensor.reshape(-1, 9, tensor.shape[2], tensor.shape[3])\n",
    "        reshaped_list.append(reshaped)\n",
    "    all_val_losses = torch.cat(reshaped_list, dim=0).numpy()\n",
    "\n",
    "    # test_losses = channel_loss(model, test_data_loader)\n",
    "    # reshaped_list = []\n",
    "    # for tensor in test_losses:\n",
    "    #     batch_size = tensor.shape[0]\n",
    "    #     reshaped = tensor.reshape(-1, 9, tensor.shape[2], tensor.shape[3])\n",
    "    #     reshaped_list.append(reshaped)\n",
    "    # all_test_losses = torch.cat(reshaped_list, dim=0).numpy()\n",
    "\n",
    "    # np.save(f\"{model_precomputes_save_folder_path}all_train_losses.npy\",all_train_losses, allow_pickle=True)\n",
    "    # np.save(f\"{model_precomputes_save_folder_path}all_val_losses.npy\",all_val_losses, allow_pickle=True)\n",
    "    # np.save(f\"{model_precomputes_save_folder_path}all_test_losses.npy\",all_test_losses, allow_pickle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot loss distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a 3×3 grid of plots\n",
    "fig, axes = plt.subplots(3, 3, figsize=(15, 12))\n",
    "axes = axes.flatten()\n",
    "# Plot histograms for each of the 9 components\n",
    "for i in range(9):\n",
    "    ax = axes[i]\n",
    "    \n",
    "    # Flatten the pixel values for this component\n",
    "    # train_pixels = all_train_losses[::100, i, :, :].flatten()\n",
    "    val_pixels = all_val_losses[::100, i, :, :].flatten()\n",
    "    # test_pixels = all_test_losses[::100, i, :, :].flatten()\n",
    "    \n",
    "    # Create histograms with transparency\n",
    "    # ax.hist(train_pixels, bins=50, alpha=0.5, color='blue', label='Train')\n",
    "    # ax.hist(test_pixels, bins=50, alpha=0.5, color='red', label='Test')\n",
    "    ax.hist(val_pixels, bins=50, alpha=0.5, color='green', label='Validation')\n",
    "    \n",
    "    ax.set_title(f'Channel {i} loss distribution')\n",
    "    ax.set_xlabel('Pixel Value')\n",
    "    ax.set_ylabel('Frequency')\n",
    "    ax.set_ylim(0, 1000)\n",
    "    ax.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate percentiles of the loss values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshaped_train = np.moveaxis(all_train_losses, 0, 1).reshape(9,-1)\n",
    "reshaped_val = np.moveaxis(all_val_losses, 0, 1).reshape(9,-1)\n",
    "# reshaped_test = np.moveaxis(all_test_losses, 0, 1).reshape(9,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_95 = np.percentile(reshaped_train[:,::100], 95, axis=1)\n",
    "# train_99 = np.percentile(reshaped_train[:,::100], 99, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_95 = np.percentile(reshaped_val[:,::100], 95, axis=1)\n",
    "val_99 = np.percentile(reshaped_val[:,::100], 99, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_95 = np.percentile(reshaped_test[:,::100], 95, axis=1)\n",
    "# test_99 = np.percentile(reshaped_test[:,::100], 99, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"95th Percentile\")\n",
    "# print(\"Train: \", train_95)\n",
    "print(\"Val: \", val_95)\n",
    "# print(\"Test: \", test_95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"99th Percentile\")\n",
    "# print(\"Train: \", train_99)\n",
    "print(\"Val: \", val_99)\n",
    "# print(\"Test: \", test_99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.save(f\"{model_precomputes_save_folder_path}thresholds_train_99\", train_99)\n",
    "np.save(f\"{model_precomputes_save_folder_path}thresholds_val_99\", val_99)\n",
    "# np.save(f\"{model_precomputes_save_folder_path}thresholds_test_99\", test_99)\n",
    "\n",
    "\n",
    "# np.save(f\"{model_precomputes_save_folder_path}thresholds_train_95\", train_95)\n",
    "np.save(f\"{model_precomputes_save_folder_path}thresholds_val_95\", val_95)\n",
    "# np.save(f\"{model_precomputes_save_folder_path}thresholds_test_95\", test_95)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "musero",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
